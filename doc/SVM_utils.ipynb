{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed33605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy\n",
    "\n",
    "# draw: [float] -> int\n",
    "# pick an index from the given list of floats proportionally\n",
    "# to the size of the entry (i.e. normalize to a probability\n",
    "# distribution and draw according to the probabilities).\n",
    "def draw(weights):\n",
    "   choice = random.uniform(0, sum(weights))\n",
    "   choiceIndex = 0\n",
    "\n",
    "   for weight in weights:\n",
    "      choice -= weight\n",
    "      if choice <= 0:\n",
    "         return choiceIndex\n",
    "\n",
    "      choiceIndex += 1\n",
    "\n",
    "\n",
    "# normalize a distribution\n",
    "def normalize(weights):\n",
    "   norm = sum(weights)\n",
    "   return tuple(m / norm for m in weights)\n",
    "\n",
    "\n",
    "def sign(x):\n",
    "   return 1 if x >= 0 else 0\n",
    "\n",
    "\n",
    "def zeroOneSign(x):\n",
    "\treturn 1 if x >= 0 else 0\n",
    "\n",
    "\n",
    "def median(L):\n",
    "    L.sort()\n",
    "    half = int(len(L) / 2)\n",
    "    if len(L) % 2 == 0:\n",
    "        return (L[half+1] + L[half]) / 2.0\n",
    "    else:\n",
    "        return L[half]\n",
    "\n",
    "\n",
    "def avg(L):\n",
    "   return sum(L) / len(L)\n",
    "\n",
    "\n",
    "def variance(L):\n",
    "   average = avg(L)\n",
    "   squaredDeviations = [(x - average)**2 for x in L]\n",
    "   return (1 / (len(L) - 1)) * sum(squaredDeviations)\n",
    "\n",
    "\n",
    "def column(A, j):\n",
    "   return [row[j] for row in A]\n",
    "\n",
    "\n",
    "def transpose(A):\n",
    "   return [column(A, j) for j in range(len(A[0]))]\n",
    "\n",
    "\n",
    "# take any function f which produces a number and produce a function which\n",
    "# outputs aggregate statistics from calling f n times.\n",
    "def errorBars(n):\n",
    "   def errorbarDecorator(f):\n",
    "      def newF(*args):\n",
    "         results = [f(*args) for _ in range(n)]\n",
    "         return avg(results), min(results), max(results), variance(results)\n",
    "      return newF\n",
    "   return errorbarDecorator\n",
    "\n",
    "\n",
    "# compute coordinatewise error bars for an array-valued function\n",
    "def arrayErrorBars(n):\n",
    "   def errorbarDecorator(f):\n",
    "      def newF(*args):\n",
    "         results = [f(*args) for _ in range(n)]\n",
    "         return [(avg(x), min(x), max(x), variance(x)) for x in transpose(results)]\n",
    "      return newF\n",
    "   return errorbarDecorator\n",
    "\n",
    "\n",
    "# compute the min and return the argument providing the min\n",
    "def argmin(L):\n",
    "   if len(L) == 0:\n",
    "      raise ValueError(\"Empty list\")\n",
    "\n",
    "   theMin = L[0]\n",
    "   minIndex = 0\n",
    "\n",
    "   for i,x in enumerate(L, start=1):\n",
    "      if x < theMin:\n",
    "         minIndex = i\n",
    "         theMin = x\n",
    "\n",
    "   return minIndex, theMin\n",
    "\n",
    "#normalize a matrix such that each entry is between 0 and 1\n",
    "def normalize01(data):\n",
    "   a = [min(row[j] for row in data) for j in range(len(data[0]))]\n",
    "   b = [max(row[j] for row in data) for j in range(len(data[0]))]\n",
    "   return [tuple([(row[j]-a[j])/(b[j]-a[j]) if b[j]!=a[j] else 0 for j in range(len(row))]) for row in data]\n",
    "\n",
    "def lpNorm(v, p):\n",
    "   return math.pow(sum(math.pow(abs(x), p) for x in v), 1/p)\n",
    "\n",
    "def lpDistance(u, v, p):\n",
    "   assert len(u)==len(v)\n",
    "   return lpNorm([u[i]-v[i] for i in range(len(u))], p)\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "   return 1.0 / (1 + numpy.exp(-z))\n",
    " \n",
    "def experimentCrossValidate(Train, Test, learner, times, statistics, protectedIndex, protectedValue, massage=False):\n",
    "   PI = protectedIndex\n",
    "   PV = protectedValue\n",
    "   originalTrain = Train\n",
    "   originalTest = Test\n",
    "   allData = Train+Test\n",
    "   #allData= allData.values.tolist()\n",
    "   variances = [[], [], []] #error, bias, ubif\n",
    "   mins = [float('inf'), float('inf'), float('inf')]\n",
    "   maxes = [-float('inf'), -float('inf'), -float('inf')]\n",
    "   avgs = [0, 0, 0]\n",
    "   \n",
    "   for time in range(times):\n",
    "     random.shuffle(allData)\n",
    "     train = allData[:len(originalTrain)]\n",
    "     test = allData[len(originalTrain):]\n",
    "     if not massage:\n",
    "       classifier_t = learner(train, protectedIndex, protectedValue)\n",
    "       output = statistics(train, test, PI, PV, learner)\n",
    "     else:\n",
    "       from massaging import randomOneSideMassageData\n",
    "       classifier_t = learner(train, protectedIndex, protectedValue)\n",
    "       output = statistics(randomOneSideMassageData, train, test, PI, PV, learner)\n",
    "     \n",
    "     for i in range(len(output)):\n",
    "       avgs[i] += (output[i][0] - avgs[i]) / (time + 1)\n",
    "       mins[i] = min(mins[i], output[i][1])\n",
    "       maxes[i] = max(maxes[i], output[i][2])\n",
    "       variances[i].append(output[i][0]) # was too lazy to implement online alg\n",
    "       # warning: this doesn't take into account the variance of each split\n",
    "   \n",
    "   for i in range(len(variances)):\n",
    "     variances[i] = variance(variances[i])\n",
    "  #prediction on test data\n",
    "   prediction=[]\n",
    "   for datapoints in Test:\n",
    "    y=classifier_t(datapoints[0])\n",
    "    prediction.append(y)\n",
    "   return prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
