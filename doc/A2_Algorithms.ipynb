{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a357af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing of the data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "df = pd.read_csv('../data/compas-scores-two-years.csv')\n",
    "features = ['race', 'age', 'sex', 'juv_misd_count', 'priors_count']\n",
    "#features chosen for our C-Logistic Regression\n",
    "to_predict = 'two_year_recid'\n",
    "races_to_filter = ['Caucasian', 'African-American']\n",
    "filtered = df.loc[df['race'].isin(races_to_filter), features + [to_predict]].reset_index(drop=True)\n",
    "\n",
    "#replace categorical data with boolean numbers, 0 and 1\n",
    "filtered['race'] = filtered['race'].apply(lambda race: 0 if race == 'Caucasian' else 1)\n",
    "filtered['sex'] = filtered['sex'].apply(lambda sex: 0 if sex == 'Male' else 1)\n",
    "#x=filtered[['race', 'age', 'sex', 'juv_misd_count', 'priors_count']]\n",
    "#y=filtered[['two_year_recid']]\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Normalizing the data, so each variable is similar in weight\n",
    "normalized_df = (filtered-filtered.mean())/filtered.std()\n",
    "filtered['age'] = normalized_df['age']\n",
    "filtered['juv_misd_count'] = normalized_df['juv_misd_count']\n",
    "filtered['priors_count'] = normalized_df['priors_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6ec63d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.33301874, -0.06273929, 18.45664809, -0.33452549,  0.16826391])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "#We adapted the code from the repository linked with our paper \"Fairness Constraints: Mechanisms for Fair Classification\"\n",
    "#utils, the file that we are importing the train_model function from is also in the doc folder of our repository\n",
    "\n",
    "from utils import train_model\n",
    "import loss_funcs\n",
    "\n",
    "train_size = 5000\n",
    "x_train = filtered.loc[:train_size, features]\n",
    "y_train = filtered.loc[:train_size, to_predict]\n",
    "x_test = filtered.loc[train_size:, features]\n",
    "y_test = filtered.loc[train_size:, to_predict]\n",
    "x_control = {'race': x_train['race'].to_list()}\n",
    "\n",
    "\n",
    "\n",
    "apply_fairness_constraints = 0\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "gamma = 0\n",
    "sensitive_attrs = []\n",
    "sensitive_attrs_to_cov_thresh = {}\n",
    "\n",
    "#coefficients from training the model\n",
    "w = train_model(x_train.to_numpy(),\n",
    "                y_train.to_numpy(),\n",
    "                x_control,\n",
    "                loss_funcs._logistic_loss,\n",
    "                apply_fairness_constraints,\n",
    "                apply_accuracy_constraint,\n",
    "                sep_constraint,\n",
    "                sensitive_attrs,\n",
    "                sensitive_attrs_to_cov_thresh,\n",
    "                gamma)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "406335c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.21      0.33       609\n",
      "           1       0.50      0.90      0.64       541\n",
      "\n",
      "    accuracy                           0.53      1150\n",
      "   macro avg       0.60      0.55      0.49      1150\n",
      "weighted avg       0.61      0.53      0.48      1150\n",
      "\n",
      "\n",
      "Total data points: 1150\n",
      "# non-protected examples: 697\n",
      "# protected examples: 453\n",
      "Non-protected in positive class: 697 (100%)\n",
      "Protected in positive class: 267 (59%)\n",
      "P-rule is: 59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpark/.local/lib/python3.8/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58.94039735099338"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "m = LogisticRegression()\n",
    "m.coef_= w.reshape((1,-1))\n",
    "m.intercept_ = 0\n",
    "m.classes_ = np.array([0, 1])\n",
    "y_pred = m.predict(x_test[features])\n",
    "print(classification_report(y_test, y_pred))\n",
    "compute_p_rule(x_test['race'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "07336fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.20439424e+01, -6.26961949e-02,  3.76846962e+02, -3.34555972e-01,\n",
       "        1.68283817e-01])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#section applying fairness constraints\n",
    "\n",
    "apply_fairness_constraints = 1\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "gamma = 0\n",
    "sensitive_attrs = ['race']\n",
    "sensitive_attrs_to_cov_thresh = {'race': 0}\n",
    "\n",
    "w = train_model(x_train.to_numpy(),\n",
    "                y_train.to_numpy(),\n",
    "                x_control,\n",
    "                loss_funcs._logistic_loss,\n",
    "                apply_fairness_constraints,\n",
    "                apply_accuracy_constraint,\n",
    "                sep_constraint,\n",
    "                sensitive_attrs,\n",
    "                sensitive_attrs_to_cov_thresh,\n",
    "                gamma)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8ab80eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.21      0.33       609\n",
      "           1       0.50      0.90      0.64       541\n",
      "\n",
      "    accuracy                           0.53      1150\n",
      "   macro avg       0.60      0.55      0.49      1150\n",
      "weighted avg       0.61      0.53      0.48      1150\n",
      "\n",
      "\n",
      "Total data points: 1150\n",
      "# non-protected examples: 697\n",
      "# protected examples: 453\n",
      "Non-protected in positive class: 697 (100%)\n",
      "Protected in positive class: 267 (59%)\n",
      "P-rule is: 59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpark/.local/lib/python3.8/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58.94039735099338"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "m = LogisticRegression()\n",
    "m.coef_= w.reshape((1,-1))\n",
    "m.intercept_ = 0\n",
    "m.classes_ = np.array([0, 1])\n",
    "y_pred = m.predict(x_test[features])\n",
    "print(classification_report(y_test, y_pred))\n",
    "compute_p_rule(x_test['race'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ca453d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut\n",
    "import loss_funcs as lf\n",
    "def test_data():\n",
    "    X, y, x_control = filtered\n",
    "    ut.compute_p_rule(x_control[\"sex\"], y) # compute the p-rule in the original data\n",
    "    \n",
    "    \"\"\" Split the data into train and test \"\"\"\n",
    "    X = ut.add_intercept(X) # add intercept to X before applying the linear classifier\n",
    "    train_fold_size = 0.7\n",
    "    x_train, y_train, x_control_train, x_test, y_test, x_control_test = ut.split_into_train_test(X, y, x_control, train_fold_size)\n",
    "    \n",
    "    apply_fairness_constraints = None\n",
    "    apply_accuracy_constraint = None\n",
    "    sep_constraint = None\n",
    "\n",
    "    loss_function = lf._logistic_loss\n",
    "    sensitive_attrs = [\"sex\"]\n",
    "    sensitive_attrs_to_cov_thresh = {}\n",
    "    gamma = None\n",
    "    \n",
    "    def train_test_classifier():\n",
    "        w = ut.train_model(x_train, y_train, x_control_train, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma)\n",
    "        train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "        distances_boundary_test = (np.dot(x_test, w)).tolist()\n",
    "        all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "        correlation_dict_test = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "        cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "        p_rule = ut.print_classifier_fairness_stats([test_score], [correlation_dict_test], [cov_dict_test], sensitive_attrs[0])\t\n",
    "        return w, p_rule, test_score\n",
    "    \n",
    "    print \n",
    "    print(\"== Unconstrained (original) classifier ==\")\n",
    "    # all constraint flags are set to 0 since we want to train an unconstrained (original) classifier\n",
    "    apply_fairness_constraints = 0\n",
    "    apply_accuracy_constraint = 0\n",
    "    sep_constraint = 0\n",
    "    w_uncons, p_uncons, acc_uncons = train_test_classifier()\n",
    "    \n",
    "    \"\"\" Now classify such that we optimize for accuracy while achieving perfect fairness \"\"\"\n",
    "    apply_fairness_constraints = 1 # set this flag to one since we want to optimize accuracy subject to fairness constraints\n",
    "    apply_accuracy_constraint = 0\n",
    "    sep_constraint = 0\n",
    "    sensitive_attrs_to_cov_thresh = {\"sex\":0}\n",
    "    print\n",
    "    print(\"== Classifier with fairness constraint ==\")\n",
    "    w_f_cons, p_f_cons, acc_f_cons  = train_test_classifier()\n",
    "    \n",
    "    \n",
    "    \"\"\" Classify such that we optimize for fairness subject to a certain loss in accuracy \"\"\"\n",
    "    apply_fairness_constraints = 0 # flag for fairness constraint is set back to0 since we want to apply the accuracy constraint now\n",
    "    apply_accuracy_constraint = 1 # now, we want to optimize fairness subject to accuracy constraints\n",
    "    sep_constraint = 0\n",
    "    gamma = 0.5 # gamma controls how much loss in accuracy we are willing to incur to achieve fairness -- increase gamme to allow more loss in accuracy\n",
    "    print(\"== Classifier with accuracy constraint ==\")\n",
    "    w_a_cons, p_a_cons, acc_a_cons = train_test_classifier()\t\n",
    "    \n",
    "    \"\"\" \n",
    "    Classify such that we optimize for fairness subject to a certain loss in accuracy \n",
    "    In addition, make sure that no points classified as positive by the unconstrained (original) classifier are misclassified.\n",
    "    \"\"\"\n",
    "    apply_fairness_constraints = 0 # flag for fairness constraint is set back to0 since we want to apply the accuracy constraint now\n",
    "    apply_accuracy_constraint = 1 # now, we want to optimize accuracy subject to fairness constraints\n",
    "    sep_constraint = 1 # set the separate constraint flag to one, since in addition to accuracy constrains, we also want no misclassifications for certain points (details in demo README.md)\n",
    "    gamma = 1000.0\n",
    "    print(\"== Classifier with accuracy constraint (no +ve misclassification) ==\")\n",
    "    w_a_cons_fine, p_a_cons_fine, acc_a_cons_fine  = train_test_classifier()\n",
    "    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e75e57e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[553 114]\n",
      " [331 232]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.83      0.71       667\n",
      "           1       0.67      0.41      0.51       563\n",
      "\n",
      "    accuracy                           0.64      1230\n",
      "   macro avg       0.65      0.62      0.61      1230\n",
      "weighted avg       0.65      0.64      0.62      1230\n",
      "\n",
      "\n",
      "Total data points: 1230\n",
      "# non-protected examples: 504\n",
      "# protected examples: 726\n",
      "Non-protected in positive class: 90 (18%)\n",
      "Protected in positive class: 256 (35%)\n",
      "P-rule is: 197%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "197.46556473829202"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "#Preproccessing\n",
    "\n",
    "features = ['race', 'age', 'sex', 'juv_misd_count', 'priors_count']\n",
    "to_predict = 'two_year_recid'\n",
    "races_to_filter = ['Caucasian', 'African-American']\n",
    "# df.loc[df['race'].isin(races_to_filter), features + [to_predict]]\n",
    "df = df.loc[df['race'].isin(races_to_filter), features + [to_predict]]\n",
    "\n",
    "\n",
    "#transform race and sex into 0 and 1 \n",
    "#African-American will be 0 and Caucasian will be 1\n",
    "#Male will be 0 and Female will be 1\n",
    "\n",
    "df['race'] = df['race'].replace(['African-American'],0)\n",
    "df['race'] = df['race'].replace(['Caucasian'],1)\n",
    "df['sex'] = df['sex'].replace(['Male'],0)\n",
    "df['sex'] = df['sex'].replace(['Female'],1)\n",
    "\n",
    "#normalize age, juv_misd_count, and priors_count\n",
    "\n",
    "normalized_df = (df-df.mean())/df.std()\n",
    "df['age'] = normalized_df['age']\n",
    "df['juv_misd_count'] = normalized_df['juv_misd_count']\n",
    "df['priors_count'] = normalized_df['priors_count']\n",
    "# normalized_df.head()\n",
    "df.head()\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X = df.drop('two_year_recid',axis=1)\n",
    "Y = df['two_year_recid']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20)\n",
    "\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#Add Fairness Constraints and p% evaluation\n",
    "compute_p_rule(X_test['race'], y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
