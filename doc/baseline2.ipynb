{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a357af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "df = pd.read_csv('../data/compas-scores-two-years.csv')\n",
    "features = ['race', 'age', 'sex', 'juv_misd_count', 'priors_count']\n",
    "to_predict = 'two_year_recid'\n",
    "races_to_filter = ['Caucasian', 'African-American']\n",
    "filtered = df.loc[df['race'].isin(races_to_filter), features + [to_predict]].reset_index(drop=True)\n",
    "\n",
    "filtered['race'] = filtered['race'].apply(lambda race: 0 if race == 'Caucasian' else 1)\n",
    "filtered['sex'] = filtered['sex'].apply(lambda sex: 0 if sex == 'Male' else 1)\n",
    "#x=filtered[['race', 'age', 'sex', 'juv_misd_count', 'priors_count']]\n",
    "#y=filtered[['two_year_recid']]\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "normalized_df = (filtered-filtered.mean())/filtered.std()\n",
    "filtered['age'] = normalized_df['age']\n",
    "filtered['juv_misd_count'] = normalized_df['juv_misd_count']\n",
    "filtered['priors_count'] = normalized_df['priors_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6ec63d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.86856785, -0.06275713, 18.53437354, -0.33472788,  0.16827645])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import train_model\n",
    "import loss_funcs\n",
    "\n",
    "train_size = 5000\n",
    "x_train = filtered.loc[:train_size, features]\n",
    "y_train = filtered.loc[:train_size, to_predict]\n",
    "x_test = filtered.loc[train_size:, features]\n",
    "y_test = filtered.loc[train_size:, to_predict]\n",
    "x_control = {'race': x_train['race'].to_list()}\n",
    "\n",
    "\n",
    "\n",
    "apply_fairness_constraints = 0\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "gamma = 0\n",
    "sensitive_attrs = ['race']\n",
    "sensitive_attrs_to_cov_thresh = {'race': 0}\n",
    "\n",
    "w = train_model(x_train.to_numpy(),\n",
    "                y_train.to_numpy(),\n",
    "                x_control,\n",
    "                loss_funcs._logistic_loss,\n",
    "                apply_fairness_constraints,\n",
    "                apply_accuracy_constraint,\n",
    "                sep_constraint,\n",
    "                sensitive_attrs,\n",
    "                sensitive_attrs_to_cov_thresh,\n",
    "                gamma)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "406335c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpark/.local/lib/python3.8/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5365217391304348"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "m = LogisticRegression()\n",
    "m.coef_= w.reshape((1,-1))\n",
    "m.intercept_ = 0\n",
    "m.classes_ = np.array([0, 1])\n",
    "(m.predict(x_test[features]) == y_test).sum() / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "07336fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_fairness_constraints = 1\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "gamma = 0\n",
    "sensitive_attrs = ['race']\n",
    "sensitive_attrs_to_cov_thresh = {'race': 0}\n",
    "\n",
    "w = train_model(x_train.to_numpy(),\n",
    "                y_train.to_numpy(),\n",
    "                x_control,\n",
    "                loss_funcs._logistic_loss,\n",
    "                apply_fairness_constraints,\n",
    "                apply_accuracy_constraint,\n",
    "                sep_constraint,\n",
    "                sensitive_attrs,\n",
    "                sensitive_attrs_to_cov_thresh,\n",
    "                gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7fe97975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61866718, 0.52736244, 0.47858317, 0.23981689, 1.0926482 ,\n",
       "       0.27346651])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8ab80eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression()\n",
    "m.coef_= w[0:5].reshape((1,-1))\n",
    "m.intercept_ = w[5]\n",
    "m.classes_=np.array([0, 1])\n",
    "x = np.array(x_test[['race', 'age', 'sex', 'juv_misd_count', 'priors_count']])\n",
    "np.unique(m.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f64f5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_fairness_constraints = 0\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "gamma = 0\n",
    "sensitive_attrs = ['race']\n",
    "sensitive_attrs_to_cov_thresh = {'race': 0}\n",
    "\n",
    "w = train_model(x_train.to_numpy(),\n",
    "                y_train.to_numpy(),\n",
    "                x_control,\n",
    "                loss_funcs._logistic_loss,\n",
    "                apply_fairness_constraints,\n",
    "                apply_accuracy_constraint,\n",
    "                sep_constraint,\n",
    "                sensitive_attrs,\n",
    "                sensitive_attrs_to_cov_thresh,\n",
    "                gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4dee9525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11993083, 0.89981818, 0.95816955, 0.48344054, 0.69401705,\n",
       "       0.01439868])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "706424fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression()\n",
    "m.coef_= w[0:5].reshape((1,-1))\n",
    "m.intercept_ = w[5]\n",
    "m.classes_=np.array([0, 1])\n",
    "x = np.array(x_test[['race', 'age', 'sex', 'juv_misd_count', 'priors_count']])\n",
    "np.unique(m.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b90c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ca453d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut\n",
    "import loss_funcs as lf\n",
    "def test_data():\n",
    "    X, y, x_control = filtered\n",
    "    ut.compute_p_rule(x_control[\"sex\"], y) # compute the p-rule in the original data\n",
    "    \n",
    "    \"\"\" Split the data into train and test \"\"\"\n",
    "    X = ut.add_intercept(X) # add intercept to X before applying the linear classifier\n",
    "    train_fold_size = 0.7\n",
    "    x_train, y_train, x_control_train, x_test, y_test, x_control_test = ut.split_into_train_test(X, y, x_control, train_fold_size)\n",
    "    \n",
    "    apply_fairness_constraints = None\n",
    "    apply_accuracy_constraint = None\n",
    "    sep_constraint = None\n",
    "\n",
    "    loss_function = lf._logistic_loss\n",
    "    sensitive_attrs = [\"sex\"]\n",
    "    sensitive_attrs_to_cov_thresh = {}\n",
    "    gamma = None\n",
    "    \n",
    "    def train_test_classifier():\n",
    "        w = ut.train_model(x_train, y_train, x_control_train, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma)\n",
    "        train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "        distances_boundary_test = (np.dot(x_test, w)).tolist()\n",
    "        all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "        correlation_dict_test = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "        cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "        p_rule = ut.print_classifier_fairness_stats([test_score], [correlation_dict_test], [cov_dict_test], sensitive_attrs[0])\t\n",
    "        return w, p_rule, test_score\n",
    "    \n",
    "    print \n",
    "    print(\"== Unconstrained (original) classifier ==\")\n",
    "    # all constraint flags are set to 0 since we want to train an unconstrained (original) classifier\n",
    "    apply_fairness_constraints = 0\n",
    "    apply_accuracy_constraint = 0\n",
    "    sep_constraint = 0\n",
    "    w_uncons, p_uncons, acc_uncons = train_test_classifier()\n",
    "    \n",
    "    \"\"\" Now classify such that we optimize for accuracy while achieving perfect fairness \"\"\"\n",
    "    apply_fairness_constraints = 1 # set this flag to one since we want to optimize accuracy subject to fairness constraints\n",
    "    apply_accuracy_constraint = 0\n",
    "    sep_constraint = 0\n",
    "    sensitive_attrs_to_cov_thresh = {\"sex\":0}\n",
    "    print\n",
    "    print(\"== Classifier with fairness constraint ==\")\n",
    "    w_f_cons, p_f_cons, acc_f_cons  = train_test_classifier()\n",
    "    \n",
    "    \n",
    "    \"\"\" Classify such that we optimize for fairness subject to a certain loss in accuracy \"\"\"\n",
    "    apply_fairness_constraints = 0 # flag for fairness constraint is set back to0 since we want to apply the accuracy constraint now\n",
    "    apply_accuracy_constraint = 1 # now, we want to optimize fairness subject to accuracy constraints\n",
    "    sep_constraint = 0\n",
    "    gamma = 0.5 # gamma controls how much loss in accuracy we are willing to incur to achieve fairness -- increase gamme to allow more loss in accuracy\n",
    "    print(\"== Classifier with accuracy constraint ==\")\n",
    "    w_a_cons, p_a_cons, acc_a_cons = train_test_classifier()\t\n",
    "    \n",
    "    \"\"\" \n",
    "    Classify such that we optimize for fairness subject to a certain loss in accuracy \n",
    "    In addition, make sure that no points classified as positive by the unconstrained (original) classifier are misclassified.\n",
    "    \"\"\"\n",
    "    apply_fairness_constraints = 0 # flag for fairness constraint is set back to0 since we want to apply the accuracy constraint now\n",
    "    apply_accuracy_constraint = 1 # now, we want to optimize accuracy subject to fairness constraints\n",
    "    sep_constraint = 1 # set the separate constraint flag to one, since in addition to accuracy constrains, we also want no misclassifications for certain points (details in demo README.md)\n",
    "    gamma = 1000.0\n",
    "    print(\"== Classifier with accuracy constraint (no +ve misclassification) ==\")\n",
    "    w_a_cons_fine, p_a_cons_fine, acc_a_cons_fine  = train_test_classifier()\n",
    "    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67d58185",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_control_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-30cc02425046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mapply_accuracy_constraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msep_constraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mw_uncons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_uncons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_uncons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-58376a872d94>\u001b[0m in \u001b[0;36mtrain_test_classifier\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_test_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_control_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fairness_constraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_accuracy_constraint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep_constraint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_attrs_to_cov_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_answers_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_answers_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdistances_boundary_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_class_labels_assigned_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances_boundary_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_control_train' is not defined"
     ]
    }
   ],
   "source": [
    "apply_fairness_constraints = 0\n",
    "apply_accuracy_constraint = 0\n",
    "sep_constraint = 0\n",
    "w_uncons, p_uncons, acc_uncons = train_test_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75e57e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bdd4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e020f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
